{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrQQUpz3c_0W",
        "outputId": "1ecd4cf3-0088-4757-9a38-b95444553475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchaudio.transforms as T\n",
        "import torchvision.io as io\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "from pydub.effects import strip_silence\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS\n",
        "duration_seconds = 4\n",
        "sample_rate = 44100\n",
        "hyper_params = {\n",
        "    'duration': duration_seconds*sample_rate,\n",
        "     'n_mels': 128,\n",
        "    'hop_length': 512,\n",
        "    'n_fft': 2048,\n",
        "    'fmin': 20,\n",
        "    'fmax': sample_rate//2\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def audio_preprocess(file_path):\n",
        "  waveform, sample_rate = librosa.load(file_path, sr=44100)\n",
        "  \n",
        "   #normalising the waveform since each audio file has the amplitude values in different ranges\n",
        "  waveform = waveform / np.max(np.abs(waveform))\n",
        "\n",
        "  #keeping values greater than threshold \n",
        "  waveform, index = librosa.effects.trim(waveform, top_db=60)\n",
        "\n",
        "  # keeping values greater than threshold = 0.001\n",
        "  wav = np.abs(waveform)\n",
        "  mask = wav > 0.001     # 0.001 is equivalent to a 60db threshold\n",
        "  waveform = waveform[mask]\n",
        "  \n",
        "  # pad to a length of 4s\n",
        "  if len(waveform) > hyper_params['duration']:\n",
        "      waveform = waveform[:hyper_params['duration']]\n",
        "  else:\n",
        "      padding = hyper_params['duration'] - len(waveform)\n",
        "      offset = padding // 2\n",
        "      waveform = np.pad(waveform, (offset, hyper_params['duration'] - len(waveform) - offset), 'constant')\n",
        "\n",
        "  return waveform, sample_rate\n",
        "\n",
        "def create_melspec(params, waveform, sampling_rate):\n",
        "  S = librosa.feature.melspectrogram(  y=waveform,\n",
        "                                       sr=sampling_rate,\n",
        "                                       n_mels=params['n_mels'],\n",
        "                                       hop_length=params['hop_length'],\n",
        "                                       n_fft=params['n_fft'],\n",
        "                                       fmin=params['fmin'],\n",
        "                                       fmax=params['fmax'])\n",
        "  S_db = librosa.power_to_db(S, ref=np.max)\n",
        "  S_db = S_db.astype(np.float32)\n",
        "\n",
        "  return S_db\n",
        "\n",
        "def display_audio(audio_file_path):\n",
        "  waveform, sample_rate = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "  # Plot the waveform\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  librosa.display.specshow(sb, sr=samplerate, hop_length=hyper_params['hop_length'], x_axis='time', y_axis='mel')\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.ylabel('Mel Frequency')\n",
        "  plt.title('Mel Spectogram',audio_file_path)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG4M9TP3dCzz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define directory paths\n",
        "data_dir = '/content/drive/My Drive/DLproject-Numpy'\n",
        "output_dir = '/content/drive/My Drive/DLproject-Numpy/augmented_spectograms'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load the class distribution\n",
        "class_distribution = {\n",
        "    \"dog_barking\": 640,\n",
        "    \"car_horn\": 344,\n",
        "    \"Fart\": 291,\n",
        "    \"Guitar\": 548,\n",
        "    \"drilling\": 560,\n",
        "    \"Gunshot_and_gunfire\": 448,\n",
        "    \"Hi-hat\": 171,\n",
        "    \"Knock\": 168,\n",
        "    \"Splash_and_splatter\": 174,\n",
        "    \"Snare_drum\": 449,\n",
        "    \"Shatter\": 212,\n",
        "    \"Laughter\": 295,\n",
        "    \"siren\": 560\n",
        "}\n",
        "\n",
        "# Define threshold for underrepresented classes\n",
        "threshold = max(class_distribution.values())  # You can adjust this threshold based on your dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "wuLkORFhdElD",
        "outputId": "8f363d5a-2bea-4f6a-b880-6dc75be0dbb8"
      },
      "outputs": [],
      "source": [
        "def augment_spectrograms(class_distribution, data_dir, output_dir, time_mask_param = 80,\n",
        "                         freq_mask_param = 80):\n",
        "    # Iterate over the class distribution\n",
        "    for class_name, num_samples in class_distribution.items():\n",
        "        if num_samples < threshold:\n",
        "            # Calculate augmentation factor needed for this class\n",
        "            augmentation_factor = int(np.ceil(threshold / num_samples))\n",
        "            # Load mel spectrograms for the underrepresented class\n",
        "            class_dir = os.path.join(data_dir, 'train', class_name)  # Adjust the path here\n",
        "            for mel_file in os.listdir(class_dir):\n",
        "                mel_path = os.path.join(class_dir, mel_file)\n",
        "\n",
        "                mel_spec = np.load(mel_path)['mel_spec']\n",
        "                augmented_spectogram = mel_spec.clone()\n",
        "\n",
        "                for i in range(augmentation_factor):\n",
        "                    time_masking = T.TimeMasking(time_mask_param=80)\n",
        "                    freq_masking = T.FrequencyMasking(freq_mask_param=80)\n",
        "\n",
        "                    # APPLY TIME MASKING\n",
        "                    augmented_spectogram = time_masking(augmented_spectogram)\n",
        "\n",
        "                    # APPLY FREQUENCY MASKING\n",
        "                    augmented_spectogram = freq_masking(augmented_spectogram)\n",
        "\n",
        "                    output_class_dir = os.path.join(output_dir, class_name)\n",
        "                    os.makedirs(output_class_dir, exist_ok=True)\n",
        "\n",
        "                    output_npz_path = os.path.join(output_class_dir, f\"original_{mel_file}.npz\")\n",
        "                    np.savez(output_npz_path, mel_spec=mel_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augment_spectrograms(class_distribution, data_dir, output_dir)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
