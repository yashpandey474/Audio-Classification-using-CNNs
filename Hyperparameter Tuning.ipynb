{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0efb2ce-aed4-473d-bdd9-63fbef765c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import librosa.display\n",
    "import librosa\n",
    "import zipfile\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from PIL import Image\n",
    "import copy\n",
    "from collections import Counter\n",
    "import cv2\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce718db-1cda-460d-acb2-3081ecd431fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from melspecdataset import MelSpecDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b7b3e7-a70a-493f-a225-9192dca4833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),  # Optionally resize images\n",
    "    transforms.ToTensor(),            # Convert images to tensors\n",
    "])\n",
    "\n",
    "\n",
    "# Define the mapping from class names to class indices\n",
    "class_mapping = {\n",
    "    'car_horn': 1,\n",
    "    'dog_barking': 2,\n",
    "    'drilling': 3,\n",
    "    'Fart': 4,\n",
    "    'Guitar': 5,\n",
    "    'Gunshot_and_gunfire': 6,\n",
    "    'Hi-hat': 7,\n",
    "    'Knock': 8,\n",
    "    'Laughter': 9,\n",
    "    'Shatter': 10,\n",
    "    'siren': 11,\n",
    "    'Snare_drum': 12,\n",
    "    'Splash_and_splatter': 13\n",
    "}\n",
    "\n",
    "# Define the directories\n",
    "train_directory = \"train\"\n",
    "val_directory = \"val\"\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MelSpecDataset(train_directory, class_mapping, transform)\n",
    "val_dataset = MelSpecDataset(val_directory, class_mapping, transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "datasets = {\"train\": train_dataset, \"val\": val_dataset}\n",
    "dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812d7e33-27bb-4372-ad60-c5c243d8aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Snare_drum': 1000,\n",
       "  'siren': 1000,\n",
       "  'Hi-hat': 1000,\n",
       "  'Gunshot_and_gunfire': 1000,\n",
       "  'car_horn': 1000,\n",
       "  'drilling': 1000,\n",
       "  'Guitar': 1000,\n",
       "  'Fart': 1000,\n",
       "  'Laughter': 1000,\n",
       "  'Splash_and_splatter': 1000,\n",
       "  'dog_barking': 1000,\n",
       "  'Shatter': 1000,\n",
       "  'Knock': 1000},\n",
       " 13000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_data, sum(train_dataset.class_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23fe08a5-3b67-4485-b609-a2f194b7c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedResNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(SimplifiedResNet, self).__init__()\n",
    "        self.in_channels = 32  # Reduced number of initial channels\n",
    "\n",
    "        # Initial convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet blocks\n",
    "        self.layer1 = self._make_layer(ResNetBlockSimple, self.in_channels, blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(ResNetBlockSimple, self.layer1[0].conv2.out_channels, blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(ResNetBlockSimple, self.layer2[0].conv2.out_channels, blocks=2, stride=2)\n",
    "\n",
    "        # Global average pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(self.layer3[0].conv2.out_channels, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ResNetBlockSimple(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlockSimple, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e604e137-9cde-449a-96a0-66a8e8ac47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        print(\"HELLO\")\n",
    "\n",
    "        #NO VALIDATION PHASE AS THAT IS HAPPENING OUT OF TRAINING [ONLY FOR HYPERPARAMETER TUNING]\n",
    "        for phase in ['train']:\n",
    "            model.train()  # Set model to training mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            index = 0\n",
    "            print(\"STARTING ITERATION\")\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "              print(\"BATCH NUMBER = \", index)\n",
    "\n",
    "              index += 1\n",
    "              optimizer.zero_grad()\n",
    "              with torch.set_grad_enabled(phase == 'train'):\n",
    "                  outputs = model(inputs)\n",
    "                  _, preds = torch.max(outputs, 1)\n",
    "                  loss = criterion(outputs, labels)\n",
    "\n",
    "                  if phase == 'train':\n",
    "                      loss.backward()\n",
    "                      optimizer.step()\n",
    "\n",
    "              running_loss += loss.item() * inputs.size(0)\n",
    "              running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'EPOCH: {epoch} {phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df39038-50a2-4181-860a-1b81036f1163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.1.5/libexec/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-03-24 17:50:28,030] A new study created in memory with name: no-name-d4caf0e1-a31d-4014-8a2f-893706faa99b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "HELLO\n",
      "STARTING ITERATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/45/r14j5zpn55q7sh5r_dqgzfy00000gn/T/ipykernel_49945/1317807445.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "/var/folders/45/r14j5zpn55q7sh5r_dqgzfy00000gn/T/ipykernel_49945/1317807445.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  gamma = trial.suggest_uniform('gamma', 0.9, 0.99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH NUMBER =  0\n",
      "BATCH NUMBER =  1\n",
      "BATCH NUMBER =  2\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "input_shape = (128, 345, 3)\n",
    "num_classes = 13  # Assuming 14 output classes\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    gamma = trial.suggest_uniform('gamma', 0.9, 0.99)\n",
    "\n",
    "    # Instantiate the model\n",
    "    model_ft = SimplifiedResNet(input_shape, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=lr)\n",
    "    exp_lr_scheduler = lr_scheduler.ExponentialLR(optimizer_ft, gamma=gamma)\n",
    "    \n",
    "    # Train the model\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    model_ft.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in val_dataloader:\n",
    "            outputs = model_ft(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Perform hyperparameter optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_lr = study.best_params['lr']\n",
    "best_gamma = study.best_params['gamma']\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(f'Best LR: {best_lr}, Best Gamma: {best_gamma}, Best Validation Accuracy: {best_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7875ff1d-f6a7-4159-9829-6fba0ecc72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape and number of classes\n",
    "\n",
    "# Instantiate the model\n",
    "model_ft = SimplifiedResNet(input_shape, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "#DIFFERENT SCHEDULER THIS TIME\n",
    "exp_lr_scheduler =  lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66072eb-a65e-4ca5-b5ce-afb9fe4569d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
