{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mtUcBE4M7Pc7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel1(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size = 5, stride = 1)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    self.lin1 = nn.Linear(in_features= 4*4*10,out_features = 100)\n",
        "    self.lin2 = nn.Linear(100,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = self.lin2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "w6nfKijX-IHJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(predictions, targets):\n",
        "  length = len(predictions)\n",
        "  correct = 0\n",
        "  for idx in range(length):\n",
        "    if predictions[idx] == targets[idx]: correct +=1\n",
        "\n",
        "  return (correct/length) * 100"
      ],
      "metadata": {
        "id": "FUGJ-pA7_WlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.unsqueeze(1)\n",
        "validation_x = validation_x.unsqueeze(1)\n",
        "test_x = test_x.unsqueeze(1) # unsqueezing to introduce batchsize"
      ],
      "metadata": {
        "id": "rfBHXhxz-IJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = CNNModel1()"
      ],
      "metadata": {
        "id": "gORuthcO_qxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_epochs = 20\n",
        "num_batches_per_train_epoch = train_x.shape[0] // batch_size\n",
        "num_batches_validation = validation_x.shape[0] // batch_size"
      ],
      "metadata": {
        "id": "H1Y2CQzR-IMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "c3ITCy4g-IOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_x, train_y, validation_x, validation_y):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  train_preds = list()\n",
        "  train_targets = list()\n",
        "\n",
        "\n",
        "    # Train one epoch\n",
        "  for batch_idx in range(num_batches_per_train_epoch):\n",
        "    optimizer.zero_grad()  # This line is necessary to flush out the gradients of the previous batch.\n",
        "\n",
        "    input = train_x[batch_idx*batch_size: (batch_idx+1)*batch_size] # Slice out batch_size amount of the training data\n",
        "    output = model(input)\n",
        "    target_out = train_y[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "    preds = torch.argmax(output, dim=1)\n",
        "\n",
        "    train_preds +=(list(preds.detach().cpu().numpy()))\n",
        "    train_targets+=(list(target_out.detach().cpu().numpy()))\n",
        "    batch_loss = criterion(output, target_out)\n",
        "\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += batch_loss\n",
        "  epoch_loss_ret = epoch_loss.detach().cpu() / batch_size\n",
        "\n",
        "    # Switch model to eval mode since we do not want to update our weights using test/val set images! They are for measuring performance only\n",
        "  model.eval()\n",
        "    # Training Performance at the end of epoch\n",
        "\n",
        "  val_preds = list()\n",
        "  val_targets = list()\n",
        "\n",
        "  for batch_idx in range(num_batches_validation):\n",
        "    input = validation_x[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "    output = model(input)\n",
        "    target_out = validation_y[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "    # preds = torch.argmax(output, dim=1)\n",
        "    preds = torch.max(output, 1)[1]\n",
        "\n",
        "\n",
        "    val_preds += (list(preds.detach().cpu().numpy()))\n",
        "    val_targets+=(list(target_out.detach().cpu().numpy()))\n",
        "\n",
        "  train_accuracy = get_accuracy(train_preds, train_targets)\n",
        "  val_accuracy = get_accuracy(val_preds, val_targets)\n",
        "\n",
        "  return train_accuracy, val_accuracy, epoch_loss_ret\n",
        "\n",
        "def train_model(train_x, train_y, validation_x, validation_y, model, num_epochs):\n",
        "    # Train the model\n",
        "  epoch_loss = 0\n",
        "  losses_at_each_epoch = list()\n",
        "  train_accuracies = list()\n",
        "  validation_accuracies = list()\n",
        "\n",
        "  # Forward pass -> Backward pass -> Weight update\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train_accuracy, val_accuracy, epoch_loss = train_epoch(model, train_x, train_y, validation_x, validation_y)\n",
        "\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    validation_accuracies.append(val_accuracy)\n",
        "    losses_at_each_epoch.append(epoch_loss)\n",
        "\n",
        "    print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
        "                epoch, losses_at_each_epoch[-1], train_accuracies[-1], validation_accuracies[-1]))\n",
        "\n",
        "  return model, epoch_loss, losses_at_each_epoch, train_accuracies, validation_accuracies"
      ],
      "metadata": {
        "id": "liWEUyGs_1tx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BOLvlKwH-ITL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKka76na-IV7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}