{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtUcBE4M7Pc7",
        "outputId": "aadfaf3a-f67c-4c88-ca4c-1257504fdd3d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# FILEPATH: /Users/kmpandey/Desktop/3-2/Deep Learning/Project/Notebooks/Project_1 (1).ipyn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract files from zip folder [ONLY EXECUTE ONCE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to the zip file\n",
        "zip_file_path = '/content/drive/My Drive/audio_dataset.zip'\n",
        "\n",
        "# Directory to extract the contents\n",
        "extract_dir = '/content/drive/My Drive/audio_dataset'\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents to the specified directory\n",
        "    zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get all class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/My Drive/audio_dataset/audio_dataset/train'\n",
        "classes = os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View info about duration of clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_duration_info(data):\n",
        "    duration_df = pd.DataFrame(columns=['Duration'])\n",
        "\n",
        "    # Iterate over each waveform in the list and get its duration\n",
        "    for i, waveform in enumerate(train_data):\n",
        "        duration = librosa.get_duration(y=waveform)\n",
        "        duration_df.loc[i] = duration\n",
        "\n",
        "    # Use .describe() to get summary statistics\n",
        "    summary_stats = duration_df.describe()\n",
        "\n",
        "    print(summary_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Functions for loading data & create mel spectograms, displaying audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_audio(file_path):\n",
        "  waveform, sample_rate = librosa.load(file_path, sr=None)\n",
        "  waveform, index = librosa.effects.trim(waveform, top_db=60)\n",
        "\n",
        "    # pad to a length of 4s\n",
        "  if len(waveform) > hyper_params['duration']:\n",
        "      waveform = waveform[:hyper_params['duration']]\n",
        "  else:\n",
        "      padding = hyper_params['duration'] - len(waveform)\n",
        "      offset = padding // 2\n",
        "      waveform = np.pad(waveform, (offset, hyper_params['duration'] - len(waveform) - offset), 'constant')\n",
        "\n",
        "  return waveform, sample_rate\n",
        "\n",
        "def create_melspec(params, audio_data, sampling_rate):\n",
        "  S = librosa.feature.melspectrogram(audio_data,\n",
        "                                       sr=sampling_rate,\n",
        "                                       n_mels=params['n_mels'],\n",
        "                                       hop_length=params['hop_length'],\n",
        "                                       n_fft=params['n_fft'],\n",
        "                                       fmin=params['fmin'],\n",
        "                                       fmax=(sampling_rate // 2))\n",
        "  Sb = librosa.power_to_db(S, ref=np.max)\n",
        "  Sb = Sb.astype(np.float32)\n",
        "\n",
        "  return Sb\n",
        "\n",
        "def load_data(data_dir):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for file_name in os.listdir(class_dir):\n",
        "            if file_name.endswith('.wav'):\n",
        "                file_path = os.path.join(class_dir, file_name)\n",
        "                waveform, sample_rate = load_audio(file_path)\n",
        "                mel_spec = create_melspec(hyper_params, waveform, sample_rate)\n",
        "                data.append(mel_spec)\n",
        "                labels.append(class_name)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "def display_audio(audio_file_path):\n",
        "  waveform, sample_rate = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "  # Plot the waveform\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  librosa.display.waveshow(waveform, sr=sample_rate)\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.ylabel('Amplitude')\n",
        "  plt.title('Waveform of Audio File')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6nfKijX-IHJ"
      },
      "outputs": [],
      "source": [
        "class CNNModel1(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size = 5, stride = 1)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    self.lin1 = nn.Linear(in_features= 4*4*10,out_features = 100)\n",
        "    self.lin2 = nn.Linear(100,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = F.relu(self.lin1(x))\n",
        "    x = self.lin2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGM3J2RwCcCy"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            ConvBlock(in_channels=3, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128),\n",
        "            ConvBlock(in_channels=128, out_channels=256),\n",
        "            ConvBlock(in_channels=256, out_channels=512),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.PReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x, _ = torch.max(x, dim=2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUGJ-pA7_WlZ"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(predictions, targets):\n",
        "  length = len(predictions)\n",
        "  correct = 0\n",
        "  for idx in range(length):\n",
        "    if predictions[idx] == targets[idx]: correct +=1\n",
        "\n",
        "  return (correct/length) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liWEUyGs_1tx"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_x, train_y, validation_x, validation_y):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  train_preds = list()\n",
        "  train_targets = list()\n",
        "\n",
        "\n",
        "    # Train one epoch\n",
        "  for batch_idx in range(num_batches_per_train_epoch):\n",
        "    optimizer.zero_grad()  # This line is necessary to flush out the gradients of the previous batch.\n",
        "\n",
        "    input = train_x[batch_idx*batch_size: (batch_idx+1)*batch_size] # Slice out batch_size amount of the training data\n",
        "    output = model(input)\n",
        "    target_out = train_y[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "    preds = torch.argmax(output, dim=1)\n",
        "\n",
        "    train_preds +=(list(preds.detach().cpu().numpy()))\n",
        "    train_targets+=(list(target_out.detach().cpu().numpy()))\n",
        "    batch_loss = criterion(output, target_out)\n",
        "\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += batch_loss\n",
        "  epoch_loss_ret = epoch_loss.detach().cpu() / batch_size\n",
        "\n",
        "    # Switch model to eval mode since we do not want to update our weights using test/val set images! They are for measuring performance only\n",
        "  model.eval()\n",
        "    # Training Performance at the end of epoch\n",
        "\n",
        "  val_preds = list()\n",
        "  val_targets = list()\n",
        "\n",
        "  for batch_idx in range(num_batches_validation):\n",
        "    input = validation_x[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "    output = model(input)\n",
        "    target_out = validation_y[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
        "    # preds = torch.argmax(output, dim=1)\n",
        "    preds = torch.max(output, 1)[1]\n",
        "\n",
        "\n",
        "    val_preds += (list(preds.detach().cpu().numpy()))\n",
        "    val_targets+=(list(target_out.detach().cpu().numpy()))\n",
        "\n",
        "  train_accuracy = get_accuracy(train_preds, train_targets)\n",
        "  val_accuracy = get_accuracy(val_preds, val_targets)\n",
        "\n",
        "  return train_accuracy, val_accuracy, epoch_loss_ret\n",
        "\n",
        "def train_model(train_x, train_y, validation_x, validation_y, model, num_epochs):\n",
        "    # Train the model\n",
        "  epoch_loss = 0\n",
        "  losses_at_each_epoch = list()\n",
        "  train_accuracies = list()\n",
        "  validation_accuracies = list()\n",
        "\n",
        "  # Forward pass -> Backward pass -> Weight update\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train_accuracy, val_accuracy, epoch_loss = train_epoch(model, train_x, train_y, validation_x, validation_y)\n",
        "\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    validation_accuracies.append(val_accuracy)\n",
        "    losses_at_each_epoch.append(epoch_loss)\n",
        "\n",
        "    print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
        "                epoch, losses_at_each_epoch[-1], train_accuracies[-1], validation_accuracies[-1]))\n",
        "\n",
        "  return model, epoch_loss, losses_at_each_epoch, train_accuracies, validation_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwCrVxzhp6iH"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.avg_pool2d(x, 2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEhAnEjaEMJy"
      },
      "outputs": [],
      "source": [
        "# RESNETS:\n",
        "class BasicBlock(nn.Module):\n",
        "\n",
        "  expansion=1 # expansion is 1 as there is no expansion factor is basic block\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=None):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1, bias=False) # 3x3 Conv Layer\n",
        "    self.bn1 = nn.BatchNorm2d(num_features = out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.downsample = downsample\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    identity = x\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(x)\n",
        "\n",
        "    x += identity\n",
        "\n",
        "    return (self.relu(x))\n",
        "\n",
        "\n",
        "class BottleNeckBlock(nn.Module):\n",
        "\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=None):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    base_width = 64\n",
        "\n",
        "    width = int(out_channels * (base_width / 64.)) * 1\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=width, kernel_size=1, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=width)\n",
        "    self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features = width)\n",
        "    self.conv3 = nn.Conv2d(in_channels=width, out_channels=width * self.expansion , kernel_size=1, stride=stride, padding=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(num_features = width * self.expansion)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.downsample = downsample\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    identity = x\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(x)\n",
        "    x+= identity\n",
        "\n",
        "    return (self.relu(x))\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(residual)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, block, layers, num_classes):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    # resnet stem\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(num_features = self.in_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    #res-blocks\n",
        "    self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "    self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "    #classifier block\n",
        "    self.adppool = nn.AdaptiveAvgPool2d((2,2))\n",
        "    self.classifier = nn.Linear(in_features=512 * block.expansion, out_features = num_classes)\n",
        "\n",
        "  def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "\n",
        "    downsample = None\n",
        "\n",
        "    if stride!=1 or self.in_channels != out_channels * block.expansion:\n",
        "\n",
        "      downsample = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=self.in_channels, out_channels=out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(num_features=out_channels * block.expansion)\n",
        "    )\n",
        "\n",
        "    layers=[]\n",
        "\n",
        "    layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "\n",
        "    self.in_channels = out_channels * block.expansion\n",
        "\n",
        "    for i in range(1, blocks):\n",
        "      layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.adppool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    return self.classifier(x)\n",
        "\n",
        "\n",
        "class ExtendedResNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.make_layer(64, 64, 3)\n",
        "        self.layer2 = self.make_layer(64, 128, 4, stride=2)\n",
        "        self.layer3 = self.make_layer(128, 256, 6, stride=2)\n",
        "        self.layer4 = self.make_layer(256, 512, 3, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
        "        layers = []\n",
        "        layers.append(ResNetBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResNetBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#GET WAVEFORMS IN A LIST\n",
        "train_data, train_labels = load_data('/content/drive/My Drive/audio_dataset/audio_dataset/train')\n",
        "\n",
        "#GET [VAL] WAVEFORMS IN A LIST\n",
        "val_data, val_labels = load_data('/content/drive/My Drive/audio_dataset/audio_dataset/val')\n",
        "\n",
        "# One-hot encode train_labels\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_onehot = onehot_encoder.fit_transform(train_labels.reshape(-1, 1))\n",
        "\n",
        "# Get the mapping\n",
        "categories = onehot_encoder.categories_\n",
        "\n",
        "# One-hot encode val_labels using the same mapping\n",
        "val_labels_onehot = onehot_encoder.transform(val_labels.reshape(-1, 1))\n",
        "\n",
        "\n",
        "num_batches_per_train_epoch = train_data.shape[0] // hyper_params[\"batch_size\"]\n",
        "num_batches_validation = val_data.shape[0] // hyper_params[\"batch_size\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyperparameters for creation of mel spectograms & model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS\n",
        "duration_seconds = 4\n",
        "sample_rate = 22050\n",
        "hyper_params = {\n",
        "    'duration': duration_seconds*sample_rate,\n",
        "     'n_mels': 128,\n",
        "    'hop_length': 512,\n",
        "    'n_fft': 2048,\n",
        "    'fmin': 20\n",
        "}\n",
        "\n",
        "model_params = {\n",
        "    'num_epochs': 50,\n",
        "    'batch_size': 64,\n",
        "    'learning_rate': 0.001,\n",
        "    'num_clases': 10,\n",
        "    'eta_min': 1e-5,\n",
        "    't_max': 10\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDI4dVGjEML_"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model1 = Classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x = train_data.unsqueeze(1)\n",
        "validation_x = val_data.unsqueeze(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
